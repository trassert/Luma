import re
from typing import List

# –°–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã MarkdownV2
MD_V2_CHARS = r'\_*[]()~`>#+-=|{}.!'

def _escape_outside_markup(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã MarkdownV2 –í–ù–ï —Ä–∞–∑–º–µ—Ç–∫–∏.
    –†–∞–∑–º–µ—Ç–∫–∞: *...*, _..._, ~...~, ||...||, `...`, ```...```
    """
    # –®–∞–±–ª–æ–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ (–∂–∞–¥–Ω—ã–µ, –Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ)
    patterns = [
        r'\|\|.*?\|\|',  # spoiler
        r'~.*?~',        # strikethrough
        r'\*.*?\*',      # bold
        r'_.*?_',        # italic
        r'`[^`]*`',      # inline code
        r'```[\s\S]*?```'  # fenced code
    ]
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —É—á–∞—Å—Ç–∫–∏ —Ä–∞–∑–º–µ—Ç–∫–∏
    markup_spans = []
    for pattern in patterns:
        for match in re.finditer(pattern, text):
            markup_spans.append((match.start(), match.end()))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
    if not markup_spans:
        return re.sub(f'([{re.escape(MD_V2_CHARS)}])', r'\\\1', text)
    
    markup_spans.sort()
    merged = [markup_spans[0]]
    for start, end in markup_spans[1:]:
        last_start, last_end = merged[-1]
        if start <= last_end:
            merged[-1] = (last_start, max(last_end, end))
        else:
            merged.append((start, end))
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≤–Ω–µ —Ä–∞–∑–º–µ—Ç–∫–∏
    result = []
    last_end = 0
    for start, end in merged:
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–æ —Ä–∞–∑–º–µ—Ç–∫–∏
        plain = text[last_end:start]
        plain = re.sub(f'([{re.escape(MD_V2_CHARS)}])', r'\\\1', plain)
        result.append(plain)
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É –∫–∞–∫ –µ—Å—Ç—å
        result.append(text[start:end])
        last_end = end
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ—Å—Ç–∞—Ç–æ–∫
    plain = text[last_end:]
    plain = re.sub(f'([{re.escape(MD_V2_CHARS)}])', r'\\\1', plain)
    result.append(plain)
    
    return ''.join(result)

def _convert_markdown_to_v2(md_text: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç GitHub-—Å—Ç–∏–ª—å Markdown ‚Üí Telegram MarkdownV2."""
    text = md_text
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    def _heading_repl(m):
        level = len(m.group(1))
        content = m.group(2).strip()
        if level == 1: return "üî¥ *{}*\n".format(_escape_outside_markup(content))
        elif level == 2: return "üü† *{}*\n".format(_escape_outside_markup(content))
        elif level in (3, 4): return "*{}*\n".format(_escape_outside_markup(content))
        else: return "_{}_\n".format(_escape_outside_markup(content))
    
    text = re.sub(r'^(#{1,6})\s+(.*)$', _heading_repl, text, flags=re.MULTILINE)
    
    # Spoiler
    text = re.sub(r'\|\|(.*?)\|\|', r'||\1||', text)
    
    # Strikethrough
    text = re.sub(r'~~(.*?)~~', r'~\1~', text)
    
    # Bold / Italic
    text = re.sub(r'\*\*(.*?)\*\*', r'*\1*', text)
    text = re.sub(r'__(.*?)__', r'*\1*', text)
    text = re.sub(r'\*(.*?)\*', r'_\1_', text)
    text = re.sub(r'_(.*?)_', r'_\1_', text)
    
    # –ö–æ–¥
    text = re.sub(r'`([^`]*)`', r'`\1`', text)
    text = re.sub(r'```(\w*)\n([\s\S]*?)\n```', r'```\n\2\n```', text)
    
    # –¶–∏—Ç–∞—Ç—ã
    text = re.sub(r'^>\s+(.*)$', r'> \1', text, flags=re.MULTILINE)
    
    # –°–ø–∏—Å–∫–∏ –∑–∞–¥–∞—á
    text = re.sub(r'^-\s+\[x\]\s+(.*)$', r'‚úÖ \1', text, flags=re.MULTILINE)
    text = re.sub(r'^-\s+\[ \]\s+(.*)$', r'‚¨ú \1', text, flags=re.MULTILINE)
    
    # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏
    text = re.sub(r'^---\s*$', r'‚éØ‚éØ‚éØ', text, flags=re.MULTILINE)
    
    # LaTeX (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)
    text = re.sub(r'\\\((.*?)\\\)', r'`\1`', text)
    text = re.sub(r'\\\[(.*?)\\\]', r'```\n\1\n```', text)
    
    # –°—Å—ã–ª–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text = re.sub(r'!\[([^\]]*)\]\((tg://emoji[^)]+)\)', r'![\1](\2)', text)
    text = re.sub(r'!\[([^\]]*)\]\(([^)]+)\)', r'[üñº \1](\2)', text)
    text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'[\1](\2)', text)
    
    # –¢–∞–±–ª–∏—Ü—ã ‚Üí –º–æ–Ω–æ—à–∏—Ä–∏–Ω–Ω—ã–π –±–ª–æ–∫
    def _table_repl(m):
        lines = m.group(0).strip().split('\n')
        if len(lines) < 2: return ""
        header = " | ".join(cell.strip() for cell in lines[0].split('|')[1:-1])
        body = "\n".join(
            " | ".join(cell.strip() for cell in line.split('|')[1:-1])
            for line in lines[2:] if line.strip()
        )
        table = f"{header}\n{body}"
        return f"```\n{table}\n```"
    
    text = re.sub(r'(\|[^\n]+\|\s*\n\|[-:\s|]+\|\s*\n(?:\|[^\n]+\|\s*\n)+)', _table_repl, text)
    
    return text

def markdown_to_telegram_v2(md_text: str) -> str:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏."""
    v2_text = _convert_markdown_to_v2(md_text)
    return _escape_outside_markup(v2_text)

def split_message_safe(text: str, max_length: int = 4096) -> List[str]:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä –¥–ª—è MarkdownV2.
    –†–∞–∑–±–∏–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –≤ –º–µ—Å—Ç–∞—Ö, –≥–¥–µ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏.
    """
    if len(text) <= max_length:
        return [text]
    
    parts = []
    current = ""
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ç–æ–∫–µ–Ω—ã: —Ä–∞–∑–º–µ—Ç–∫–∞ –∏ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    tokens = re.findall(r'(\|\|.*?\|\||~.*?~|\*.*?\*|_.*?_|`[^`]*`|```[\s\S]*?```|.)', text)
    
    for token in tokens:
        test = current + token
        if len(test) > max_length:
            if current:
                parts.append(current)
                current = token
            else:
                # –¢–æ–∫–µ–Ω —Å–∞–º –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞ ‚Äî –¥—Ä–æ–±–∏–º –µ–≥–æ –∫–∞–∫ plain text
                subparts = _split_plain_token(token, max_length)
                if subparts:
                    parts.extend(subparts[:-1])
                    current = subparts[-1]
        else:
            current += token
    
    if current:
        parts.append(current)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –ª—é–±—ã–µ –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    safe_parts = []
    for part in parts:
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –Ω–µ–∑–∞–∫—Ä—ã—Ç—É—é —Ä–∞–∑–º–µ—Ç–∫—É
            if _has_unbalanced_markup(part):
                # –ï—Å–ª–∏ –µ—Å—Ç—å ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ plain text
                safe_parts.append(re.sub(f'([{re.escape(MD_V2_CHARS)}])', r'\\\1', part))
            else:
                safe_parts.append(part)
        except Exception:
            safe_parts.append(re.sub(f'([{re.escape(MD_V2_CHARS)}])', r'\\\1', part))
    
    return safe_parts

def _split_plain_token(token: str, max_len: int) -> List[str]:
    """–î—Ä–æ–±–∏—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª–æ–≤–æ) –Ω–∞ —á–∞—Å—Ç–∏."""
    if len(token) <= max_len:
        return [token]
    parts = []
    while token:
        if len(token) <= max_len:
            parts.append(token)
            break
        parts.append(token[:max_len])
        token = token[max_len:]
    return parts

def _has_unbalanced_markup(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –Ω–µ–∑–∞–∫—Ä—ã—Ç–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞."""
    pairs = {'*': 0, '_': 0, '~': 0, '|': 0, '`': 0}
    i = 0
    while i < len(text):
        c = text[i]
        if c == '\\' and i + 1 < len(text):
            i += 2  # —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª
            continue
        if c == '`':
            if i + 2 < len(text) and text[i:i+3] == '```':
                # fenced code ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
                end = text.find('```', i+3)
                if end == -1:
                    return True
                i = end + 3
                continue
            else:
                pairs['`'] = (pairs['`'] + 1) % 2
        elif c in pairs:
            pairs[c] = (pairs[c] + 1) % 2
        i += 1
    return any(count != 0 for count in pairs.values())